Parameters:
  vpcID:
    Description: The ID of your VPC (leave blank if using the default VPC).
    Type: String
    AllowedPattern: vpc-[a-z0-9]{8}
    ConstraintDescription: Malformed input parameter - vpcID must match pattern vpc-[a-z0-9]{8}
Resources:
  kubernetesControlPlane:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Timeout: PT5M
    Properties:
      ImageId: ami-07b36ea9852e986ad
      KeyName: K8sKeyPair
      SecurityGroupIds:
        - !GetAtt kubernetesControlPlaneSecurityGroup.GroupId
      InstanceType: t2.medium
      Tags:
        - Key: Name
          Value: k8s-control-lab
      IamInstanceProfile: K8sEC2InstanceProfile 
      BlockDeviceMappings:
              - DeviceName: /dev/sda1
                Ebs:
                  VolumeType: gp2
                  VolumeSize: '30'
                  DeleteOnTermination: 'true'
                  Encrypted: 'true'
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -x

          # # Install prereqs, aws cfn helper scripts, and the awscli. # #
          apt update && apt install -y -qq python3-pip && apt install -y -qq curl
          pip install --quiet https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-py3-latest.tar.gz
          mkdir ~/aws-cfn-bootstrap && cd ~/aws-cfn-bootstrap
          curl https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-py3-latest.tar.gz -o aws-cfn-bootstrap.tar.gz
          tar -xf ./aws-cfn-bootstrap.tar.gz
          ln -s ./aws-cfn-bootstrap-2.0/init/ubuntu/cfn-hup /etc/init.d/cfn-hup
          apt install -y unzip
          mkdir ~/awscli && cd ~/awscli && curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -qq awscliv2.zip
          sudo ./aws/install
          
          # # System level configuration prereqs # #
          hostnamectl set-hostname k8s-control
          ipvar=$(hostname -I)
          echo $ipvar k8s-control | tee -a /etc/hosts ~/newHosts
          echo "${kubernetesWorker1.PrivateIp} k8s-worker1" | tee -a /etc/hosts ~/newHosts
          echo "${kubernetesWorker2.PrivateIp} k8s-worker2" | tee -a /etc/hosts ~/newHosts
          touch /etc/modules-load.d/k8s.conf
          echo overlay >> /etc/modules-load.d/k8s.conf
          echo br_netfilter >> /etc/modules-load.d/k8s.conf
          modprobe overlay
          modprobe br_netfilter
          touch /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-iptables  = 1 >> /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-ip6tables = 1 >> /etc/sysctl.d/k8s.conf
          echo net.ipv4.ip_forward                 = 1 >> /etc/sysctl.d/k8s.conf
          sysctl --system
          
          # # Install containerd, setup K8s package repo, install kubelet, kubeam, and kubectl # #
          apt-get update && apt-get install -y containerd
          mkdir /etc/containerd
          containerd config default | sudo tee /etc/containerd/config.toml
          systemctl restart containerd
          swapoff -a
          apt-get update && apt-get install -y apt-transport-https ca-certificates gpg
          mkdir -p -m 755 /etc/apt/keyrings
          curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
          echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
          apt-get update && apt-get install -y kubelet kubeadm kubectl
          apt-mark hold kubelet kubeadm kubectl
          
          # # Initialize the cluster, install pod networking plugin # #
          kubeadm init --pod-network-cidr 192.168.0.0/16
          export KUBECONFIG=/etc/kubernetes/admin.conf
          echo "KUBECONFIG=/etc/kubernetes/admin.conf" >> /etc/environment
          while ! kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml; do echo "Trying to apply Calico again in 5 seconds..."; sleep 5; done
          
          # # Pass configurations and cluster join command to worker nodes via AWS SSM # #
          joinCommand=$(kubeadm token create --print-join-command)
          aws ssm send-command --instance-ids "${kubernetesWorker1}" --document-name AWS-RunShellScript --parameters '{"commands":["echo '"$ipvar"' k8s-control >> /etc/hosts","echo '"${kubernetesWorker2.PrivateIp}"' k8s-worker2 >> /etc/hosts","'"$joinCommand"'"]}' --output text
          aws ssm send-command --instance-ids "${kubernetesWorker2}" --document-name AWS-RunShellScript --parameters '{"commands":["echo '"$ipvar"' k8s-control >> /etc/hosts","echo '"${kubernetesWorker1.PrivateIp}"' k8s-worker1 >> /etc/hosts","'"$joinCommand"'"]}' --output text
      
          # # Pass success signal to AWS CloudFormation # #
          cfn-signal --stack ${AWS::StackName} --resource kubernetesControlPlane --region ${AWS::Region}
    DependsOn:
      - ec2InstanceProfileRole
      - kubernetesWorkersSecurityGroup
      - ec2KeyPair
      - kubernetesWorker1
      - kubernetesWorker2
  kubernetesWorker1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-07b36ea9852e986ad
      KeyName: K8sKeyPair
      SecurityGroupIds:
        - !GetAtt kubernetesWorkersSecurityGroup.GroupId
      InstanceType: t2.medium
      Tags:
        - Key: Name
          Value: k8s-worker1-lab
      IamInstanceProfile: K8sEC2InstanceProfile
      BlockDeviceMappings:
              - DeviceName: /dev/sda1
                Ebs:
                  VolumeType: gp2
                  VolumeSize: '30'
                  DeleteOnTermination: 'true'
                  Encrypted: 'true'    
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -x
          
          # # System level configuration prereqs # #
          hostnamectl set-hostname k8s-worker1
          ipvar=$(hostname -I)
          echo $ipvar k8s-worker1 >> /etc/hosts
          touch /etc/modules-load.d/k8s.conf
          echo overlay >> /etc/modules-load.d/k8s.conf
          echo br_netfilter >> /etc/modules-load.d/k8s.conf
          modprobe overlay
          modprobe br_netfilter
          touch /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-iptables  = 1 >> /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-ip6tables = 1 >> /etc/sysctl.d/k8s.conf
          echo net.ipv4.ip_forward                 = 1 >> /etc/sysctl.d/k8s.conf
          sysctl --system

          # # Install containerd, setup K8s package repo, install kubelet, kubeam, and kubectl # #
          apt-get update && apt-get install -y containerd
          mkdir /etc/containerd
          containerd config default | sudo tee /etc/containerd/config.toml
          systemctl restart containerd
          swapoff -a
          apt-get update && apt-get install -y apt-transport-https ca-certificates curl gpg
          mkdir -p -m 755 /etc/apt/keyrings
          curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
          echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
          apt-get update && apt-get install -y kubelet kubeadm kubectl
          apt-mark hold kubelet kubeadm kubectl
    DependsOn:
      - ec2InstanceProfileRole
      - kubernetesWorkersSecurityGroup
      - ec2KeyPair
  kubernetesWorker2:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-07b36ea9852e986ad
      KeyName: K8sKeyPair
      SecurityGroupIds:
        - !GetAtt kubernetesWorkersSecurityGroup.GroupId
      InstanceType: t2.medium
      Tags:
        - Key: Name
          Value: k8s-worker2-lab
      IamInstanceProfile: K8sEC2InstanceProfile
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeType: gp2
            VolumeSize: '30'
            DeleteOnTermination: 'true'
            Encrypted: 'true'
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -x
          
          # # System level configuration prereqs # #
          hostnamectl set-hostname k8s-worker2
          ipvar=$(hostname -I)
          echo $ipvar k8s-worker2 >> /etc/hosts
          touch /etc/modules-load.d/k8s.conf
          echo overlay >> /etc/modules-load.d/k8s.conf
          echo br_netfilter >> /etc/modules-load.d/k8s.conf
          modprobe overlay
          modprobe br_netfilter
          touch /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-iptables  = 1 >> /etc/sysctl.d/k8s.conf
          echo net.bridge.bridge-nf-call-ip6tables = 1 >> /etc/sysctl.d/k8s.conf
          echo net.ipv4.ip_forward                 = 1 >> /etc/sysctl.d/k8s.conf
          sysctl --system

          # # Install containerd, setup K8s package repo, install kubelet, kubeam, and kubectl # #
          apt-get update && apt-get install -y containerd
          mkdir /etc/containerd
          containerd config default | sudo tee /etc/containerd/config.toml
          systemctl restart containerd
          swapoff -a
          apt-get update && apt-get install -y apt-transport-https ca-certificates curl gpg
          mkdir -p -m 755 /etc/apt/keyrings
          curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
          echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
          apt-get update && apt-get install -y kubelet kubeadm kubectl
          apt-mark hold kubelet kubeadm kubectl
    DependsOn:
      - ec2InstanceProfileRole
      - kubernetesWorkersSecurityGroup
      - ec2KeyPair
  ec2InstanceProfileRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument: '{"Version":"2012-10-17","Statement":[{"Sid":"","Effect":"Allow","Principal":{"Service":"ec2.amazonaws.com"},"Action":"sts:AssumeRole"}]}'
      RoleName: K8sEC2InstanceRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
      Policies:
        - PolicyDocument: '{"Version":"2012-10-17","Statement":[{"Sid":"VisualEditor0","Effect":"Allow","Action":"ssm:SendCommand","Resource":["arn:aws:ssm:*::document/AWS-RunShellScript","arn:aws:ec2:*:367523064903:instance/*"]}]}'
          PolicyName: AdditionalSSMPermissions
  ec2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: K8sEC2InstanceProfile
      Roles: 
        - Ref: ec2InstanceProfileRole
    DependsOn:
      - ec2InstanceProfileRole
  kubernetesControlPlaneSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for
      GroupName: kubernetesControlPlaneSecurityGroup
      VpcId: !Ref vpcID
      SecurityGroupEgress: 
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: All traffic outbound IPv4
      SecurityGroupIngress: 
        - IpProtocol: -1
          SourceSecurityGroupId: !GetAtt kubernetesWorkersSecurityGroup.GroupId
          Description: All traffic from worker nodes
  kubernetesWorkersSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for
      GroupName: kubernetesWorkersSecurityGroup
      VpcId: !Ref vpcID
      SecurityGroupEgress: 
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: All traffic outbound IPv4
  WorkerSecurityGroupIngress: 
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      IpProtocol: -1
      GroupId: !GetAtt kubernetesWorkersSecurityGroup.GroupId
      SourceSecurityGroupId: !GetAtt kubernetesControlPlaneSecurityGroup.GroupId
      Description: All traffic from control plane node
    DependsOn: 
    - kubernetesControlPlaneSecurityGroup
    - kubernetesWorkersSecurityGroup
  ec2KeyPair:
    Type: AWS::EC2::KeyPair
    Properties:
      KeyFormat: ppk
      KeyName: K8sEc2KeyPair